apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ds
  labels:
    tier: ds
    app: ds
spec:
  selector:
    matchLabels:
      app: ds
  serviceName: ds
  replicas: 1
  template:
    metadata:
      labels:
        tier: ds
    spec:
      # Attempt to spread out ds containers across zones
      topologySpreadConstraints:
      - maxSkew: 1
        topologyKey: topology.kubernetes.io/zone
        # Use DoNotSchedule if you want to prevent ds pods from being scheduled in the same zone
        whenUnsatisfiable: ScheduleAnyway
        labelSelector:
          matchLabels:
            app: ds
      # Create a toleration that allows this pod to be scheduled on a tainted node
      # This is used to drive directory instances to dedicated nodes for performance.
      # If a node is not tainted, this has no impact.
      tolerations:
      - key: "WorkerDedicatedDS"
        operator: "Exists"
      initContainers:
      - name: initialize
        image: ds
        imagePullPolicy: Always
        args: ["init"]
        volumeMounts:
        - name: data
          mountPath: /opt/opendj/data
        - name: passwords
          mountPath: /var/run/secrets/opendj-passwords
        - name: ds-ssl-keypair
          mountPath: /var/run/secrets/ds-ssl-keypair
        - name: ds-ssl-keypair
          mountPath: /var/run/secrets/truststore
        - name: ds-master-keypair
          mountPath: /var/run/secrets/ds-master-keypair
        - name: keys
          mountPath: /var/run/secrets/keys      
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1024Mi
      containers:
      - name: ds
        image: ds
        imagePullPolicy: IfNotPresent
        args: ["start-ds"]
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        ports:
          - name: ldap
            containerPort: 1389
          - name: ldaps
            containerPort: 1636
          - name: admin
            containerPort: 4444
          - name: replication
            containerPort: 8989
          - name: http
            containerPort: 8080
          - name: https
            containerPort: 8443
        resources:
          requests:
            memory: 512Mi
            cpu: 250m
          limits:
            memory: 1024Mi
        volumeMounts:
        - name: data
          mountPath: /opt/opendj/data
        - name: passwords
          mountPath: /var/run/secrets/opendj-passwords
        # These are not required at runtime because the init entrypoint sets up all the
        # keys in /var/run/secrets/keys.
        # When DS can directly consume the cert-manager secrets, these can be reenabled.
        # - name: ds-ssl-keypair
        #   mountPath: /var/run/secrets/ds-ssl-keypair
        # - name: ds-master-keypair
        #   mountPath: /var/run/secrets/ds-master-keypair
        - name: keys
          mountPath: /var/run/secrets/keys
      securityContext:
        fsGroup: 0
        runAsUser: 11111
        runAsGroup: 0
      terminationGracePeriodSeconds: 30
      volumes:
      - name: passwords
        secret:
          secretName: ds-passwords
      - name: ds-master-keypair
        secret:
          secretName: ds-master-keypair
          defaultMode: 384
      - name: ds-ssl-keypair
        secret:
          secretName: ds-ssl-keypair
          defaultMode: 384
      # Where the ds keys will get copied to.  The keys need to be a format that DS likes - not cert-manager
      # The init container copies /formats the cert-manager keys to this volume.
      - name: keys
        emptyDir: {}
  updateStrategy:
    type: RollingUpdate 
  volumeClaimTemplates:
  - metadata:
      name: data
      annotations:
        pv.beta.kubernetes.io/gid: "0"
    spec:
      # Include below storageClass in overlay if wanting to use local SSD.
      # storageClassName: "local-storage"
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 5Gi
