# Copyright (c) 2016-2017 ForgeRock AS.
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: "{{ .Values.djInstance }}-rs"
  labels:
    djInstance: "{{ .Values.djInstance }}-rs"
    app: {{ template "fullname" . }}
    vendor: forgerock
    component: {{ .Values.component }}
spec:
  serviceName: "{{ .Values.djInstance }}-rs"
  replicas: {{ .Values.replicationServer.replicas }}
  {{- if .Values.djPersistence }}
  volumeClaimTemplates:
  - metadata:
      name: data
      annotations:
        pv.beta.kubernetes.io/gid: "11111"
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: {{ default "5Gi"  .Values.replicationServer.storageSize }}
      storageClassName:  {{ .Values.replicationServer.storageClass }}
  {{- end }}
  template:
    metadata:
      labels:
        djInstance: "{{ .Values.djInstance }}-rs"
        app: {{ template "fullname" . }}
        vendor: forgerock
        component: opendj
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: djInstance
                  operator: In
                  values:
                  - {{ .Values.djInstance }}
              topologyKey: kubernetes.io/hostname
      terminationGracePeriodSeconds: 30
      # This will make sure the mounted PVCs are writable by the forgerock user with gid 111111.
      securityContext:
        fsGroup: 11111
      containers:
      - name: opendj
        image:  {{ .Values.image.repository }}:{{ .Values.image.tag }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        resources:
{{ toYaml .Values.replicationServer.resources | indent 12 }}
        envFrom:
        - configMapRef:
            name: {{ .Values.djInstance }}
        env:
        - name: DS_ROLE
          value: replication-server
        ports:
        - containerPort: 4444
          name: admin
        - containerPort: 8989
          name: replication
        - containerPort: 8081
          name: metrics
        volumeMounts:
        - name: dj-secrets
          mountPath: /var/run/secrets/opendj
        - name: dj-backup
          mountPath: /opt/opendj/backup
        {{- if .Values.djPersistence }}
        - name: data
          mountPath: /opt/opendj/data
        {{- end }}
        # For the RS we need to disable this. RS1 needs to talk to itself, and it is not available until it is READY
        # If we move the init logic to the replication script we can fix this...
#        readinessProbe:
#          tcpSocket:
#            port: metrics
#          periodSeconds: 20
#          initialDelaySeconds: 30
        livenessProbe:
          tcpSocket:
            port: metrics
          initialDelaySeconds: 60
          periodSeconds: 60
      {{- if .Values.enableGcloudBackups }}
      # An example of enabling backup to google cloud storage.
      # The bucket must exist, and the cluster needs --scopes storage-full when it is created.
      # This runs the gsutil command periodically to rsync the contents of the /backup folder (shared with the DJ container) to cloud storage. 
      - name: backup
        image: gcr.io/cloud-builders/gcloud
        imagePullPolicy: IfNotPresent
        command: [ "/bin/sh", "-c", "while true; do gsutil -m rsync -r /backup {{ .Values.gsBucket }} ; sleep 600;  done"]
        volumeMounts:
        - name: dj-backup
          mountPath: /backup
      {{- end }}
      volumes:
      - name: dj-secrets
        secret:
          secretName: {{ .Values.djInstance }}
          # If we are running as non root, we can't set this mode to root read only
          #defaultMode: 256
      - name: dj-backup
        emptyDir: {}